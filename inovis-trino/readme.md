## Задание на позицию Data Engeneer в Inovis

## Описание

Текст задания - см. файл "Тз 2023.docx"

Скрипт для создания backup баз данных представлен в папке "Basebackup script"

Файл-проект PowerBI с моделью данных и визуализацией - в папке "Basebackup script"

Коды процедуры и функции - в папке "Stored_routines". 

Процедура 'insert_procedure_info' осуществляет копирование несистемных данных о хранимых процедурах и функциях, хранящихся в системной таблице pg_proc, и копирует их в папку stored_routines.

Возникающие ошибки при исполнении процедуры сохраняются в таблице procedure_errors.

Функция 'most_popular_product' возвращает наименование наиболее популярного продукта, согласно сведениям из таблицы fact_sales.



## Шаги:

- [x] 1. Создание оперативной базы данных с 3 таблицами:
            а.Таблица продаж - sales : customerId, productId, qty
            б.Таблица клиентов - customers: id, name, country
            в.Таблица продуктов- products : id, name, groupname
- [x] 2. Создание реляционных mrr, sgt, dwh баз данных на другом инстансе от оперативной
- [x] 3. Создание ETL процесса с переходами данных из оперативной базы в mrr -> sgt -> dwh
- [x] 4. Создание системы логов, которые пишутся в созданную для этого таблицу
- [x] 5. Создание процедуры (с использованием cursor, try и catch). Ошибки пишутся в лог в созданную для этого таблицу. Создание функции. Сохранение процедуры и функции в dwh
- [x] 6. Создание дашборда и модели данных Power BI из данных в dwh
- [x] 7. Создание скрипта, выполняющего backup баз данных mrr, stg, dwh

## Tools:

Инфраструктура для решения поднята с помощью Docker

Процесс ETL организован с помощью Apache Airflow (оркестратор) и Trino (distributed SQL query engine designed to query large data sets distributed over one or more heterogeneous data sources.)

Базы данных sourse, mrr, stg, dwh - PostgreSQL (использована одна система для уменьшения количества докер образов).

Примененные языки программирования: SQL, Python, Bash   

Моделирование данных и визуализация: PowerBI (был установлен локально с подключением к dwh)


## Создание инфраструктуры проекта на основании docker-compose.yml

1. Building images

```shell
docker compose build
```

2. Initialize the metadata db

```shell
docker compose run --rm airflow-cli db init
```

3. Create an admin user

```shell
docker compose run --rm airflow-cli users create --email airflow@example.com --firstname airflow --lastname airflow --password airflow --username airflow --role Admin
```

4. Start all services

```shell
docker compose up -d
```

Поскольку подные контейнеры используют большой объем ресурсов ПК и не всегда используются одновременно, было бы рациональнее использовать Kubernetes.

## Описание ETL процесса

Создается зеркало оперативной БД в базе mrr, из которой данные передаются в стейджинговую бд stg.
Обработка, трасформация и иные необходимые действия проводяться в базе данных stg, после чего подготовленные в необходимом виде данные передаются в базу dwh.
В последующем данные, содержащиеся в бд dwh используются для анализа и визуализации.

ETL процесс реализован с помощью Apache Airflow, при построении DAG использованы TrinoOperator, PythonOperator. Использование последнего в данном случае обусловлено особенностями TrinoOperator с PostgreSQL (не может реальизовать методы изменения данных (напр. UPDATE, UPSERT, MERGE, TRUNCATE).
Open-source Trino упрощает работу с различными видами баз данных и источников хранения данных (в т.ч. объектных хранилищ) и с точки зрения написани DAG упрощает процес до использования TrinoOperator с передачей ему настроенных в Trino параметров соединения и необходимого SQL-подобного запроса в соответсвующие базы данных. 
Один недостатков такого подохода - увеличение потребности в ресурсах, из плюсов - все вычисления и логика выполнения процессов выполняется инструментом, спроектированным для обработки значительных объемов данных.

Возможно организовать осуществление операций по преобразованию данных в stg с помощью dbt, в таком случае ETL-процесс можно трасформировать в ELT (без создания stg базы данных на отдельном инстансе)

Другой возможный вариант - реализация посредством Bash/Python/Postgres-операторов, что увеличивает трудоемкость написания кода, при этом уменьшаются затраты на инфраструктуру. Представляется в таком случае передача данных из одной базы данных в другую посредством создания файлов копий соотвествующих таблиц/бд, с передачей таких файлов между серверами. 

Базы mrr, sgt, dwh подняты на одном инстансе, скрипт для создания нескольких бд - в папке Infrastructure/Pstgredocker вместе с докерфайлом
Таблицы в базах данных созданы Airflow DAG 'create_tables_in_databases', тестирование проведено на даннных, добавляемых в оперативную бд дагом 'test_data'.

Код, предствленный в etl_dag, можно улучшить:
- вынести sql-запросы во внешние файлы, расположив в папке с дагами;
- использовать написание Dynamic DAG, поскольку представленный код имеет множество одинаковых действий. Возможен такой вариант: сделать динамический даг для этапов переноса данных из операционный бд в stg, поскольку структура таблиц не изменяется, а трансформацию данных и копирование их в бд, очистка таблиц в stg - вынести в другой даг, зависящий от первого.

Настройка соединений Trino с базами данных представлена в папке Infrastructure/trino/catalog.

## Настройка логгирования

Согласно документации, мониторинг работы Airflow можно организовать:
- использованием сторонних сервисов, собирающих логи и передающих (FluentD, Logstash) их в сервис мониторинга/аналитики (Kibana).
- используя встроенную систему логов Airflow, доступную через IU или через файлы логов, хранящиеся в локально. В случая использования для хранения бэкэнда внешних БД, Airflow не рекомендует в целях безопасности обращаться работать с внутренней БД.

Расширение функционала логов можно реализовать с путем создания кастомного класса, управляющего логами (handler) используя logger-модуль Python. Код хранится в отдельном файле, при этом необходимо настроить его в файлах конфигурации airflow.
Использование кастомного обработчика логов в даге осуществляется путем импортирования такого модуля и вызова метода basicConfig(), в котором в качестве параметра указывается кастомный хэндлер.

В данном случае использованы атрибут класса DAG 'on_failure_callback' и 'on_success_callback', в которыt передаются функции 'dag_failure_callback' и 'dag_success_callback', осуществляющие логирование . Недостаток использования данного варианта - данные параметры не работают при ручном запуске дага.
